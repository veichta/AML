{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import mutual_info_regression\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import IsolationForest\n",
    "\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "import scipy\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "#import wandb\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_features(X, y, num_features):\n",
    "    model = XGBRegressor(n_estimators=100, n_jobs=-1)\n",
    "    #model = KNeighborsClassifier(n_neighbors=20)\n",
    "\n",
    "    selector = RFE(estimator=model, n_features_to_select=num_features, step=20)\n",
    "    #selector = SequentialFeatureSelector(model, n_features_to_select=num_features, n_jobs=10, cv=10)\n",
    "\n",
    "    print('[INFO] fitting selector ...')\n",
    "    selector.fit(X, y[:, 0])\n",
    "\n",
    "    # discard unimportant features\n",
    "    print('[INFO] transfroming X ...')\n",
    "    X_new = selector.transform(X)\n",
    "    print('[INFO] Done.')\n",
    "    return X_new\n",
    "\n",
    "def remove_outliers(X, y):\n",
    "    iforst = IsolationForest(n_estimators=1000, n_jobs=-1, contamination='auto')\n",
    "    #print('[INFO] fit transfrom outlier detection ...')\n",
    "    outliers = iforst.fit_predict(X)\n",
    "    mask = outliers != -1\n",
    "    X_new = X[mask, :] \n",
    "    y_new = y[mask, :]\n",
    "    #print('[INFO] Done.')\n",
    "    return X_new, y_new, mask\n",
    "\n",
    "\n",
    "def impute(X, y, k):\n",
    "    imp = KNNImputer(n_neighbors=k)\n",
    "    X_new = imp.fit_transform(X)\n",
    "    return X_new, y.values\n",
    "\n",
    "def get_score(X, y, model, scalerY):\n",
    "    y_hat = model.predict(X).reshape( (len(X), 1) )\n",
    "    y_hat = scalerY.inverse_transform(y_hat)\n",
    "\n",
    "    y_true = y.reshape( (len(y), 1) )\n",
    "    y_true = scalerY.inverse_transform(y_true)\n",
    "    return r2_score( y_true, y_hat )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "      <th>x4</th>\n",
       "      <th>x5</th>\n",
       "      <th>x6</th>\n",
       "      <th>x7</th>\n",
       "      <th>x8</th>\n",
       "      <th>x9</th>\n",
       "      <th>...</th>\n",
       "      <th>x823</th>\n",
       "      <th>x824</th>\n",
       "      <th>x825</th>\n",
       "      <th>x826</th>\n",
       "      <th>x827</th>\n",
       "      <th>x828</th>\n",
       "      <th>x829</th>\n",
       "      <th>x830</th>\n",
       "      <th>x831</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>10.891876</td>\n",
       "      <td>832442.812375</td>\n",
       "      <td>20585.544083</td>\n",
       "      <td>1028.369495</td>\n",
       "      <td>1.163780e+06</td>\n",
       "      <td>9.199135</td>\n",
       "      <td>597900.477629</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.144294e+06</td>\n",
       "      <td>785176.201298</td>\n",
       "      <td>...</td>\n",
       "      <td>-855.549602</td>\n",
       "      <td>12176.073427</td>\n",
       "      <td>10.647729</td>\n",
       "      <td>10.916371</td>\n",
       "      <td>1220.065443</td>\n",
       "      <td>8.566724</td>\n",
       "      <td>1.036263e+06</td>\n",
       "      <td>85338.558539</td>\n",
       "      <td>103088.664210</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>11.512994</td>\n",
       "      <td>832442.898114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1012.624877</td>\n",
       "      <td>1.028911e+06</td>\n",
       "      <td>10.906408</td>\n",
       "      <td>597900.458612</td>\n",
       "      <td>8127.016078</td>\n",
       "      <td>1.099166e+06</td>\n",
       "      <td>785176.258299</td>\n",
       "      <td>...</td>\n",
       "      <td>-787.397942</td>\n",
       "      <td>10493.095660</td>\n",
       "      <td>10.586492</td>\n",
       "      <td>9.463962</td>\n",
       "      <td>917.094909</td>\n",
       "      <td>10.231822</td>\n",
       "      <td>1.007163e+06</td>\n",
       "      <td>95695.020645</td>\n",
       "      <td>105161.109422</td>\n",
       "      <td>73.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>11.052185</td>\n",
       "      <td>832442.896307</td>\n",
       "      <td>20585.512844</td>\n",
       "      <td>1003.953827</td>\n",
       "      <td>9.231756e+05</td>\n",
       "      <td>9.212979</td>\n",
       "      <td>597900.426764</td>\n",
       "      <td>10738.092422</td>\n",
       "      <td>1.027863e+06</td>\n",
       "      <td>785176.223468</td>\n",
       "      <td>...</td>\n",
       "      <td>-906.997242</td>\n",
       "      <td>10959.516944</td>\n",
       "      <td>10.769287</td>\n",
       "      <td>10.342160</td>\n",
       "      <td>637.027802</td>\n",
       "      <td>10.705461</td>\n",
       "      <td>1.019955e+06</td>\n",
       "      <td>80253.299882</td>\n",
       "      <td>104177.051666</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>11.642076</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1004.672084</td>\n",
       "      <td>9.459461e+05</td>\n",
       "      <td>9.553420</td>\n",
       "      <td>597900.450367</td>\n",
       "      <td>13524.096973</td>\n",
       "      <td>1.168144e+06</td>\n",
       "      <td>785176.254867</td>\n",
       "      <td>...</td>\n",
       "      <td>-1011.742516</td>\n",
       "      <td>16845.309819</td>\n",
       "      <td>10.483830</td>\n",
       "      <td>10.594941</td>\n",
       "      <td>1114.069590</td>\n",
       "      <td>10.321063</td>\n",
       "      <td>1.085442e+06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>102746.516920</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>10.407121</td>\n",
       "      <td>832442.831424</td>\n",
       "      <td>20585.557007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.957182e+05</td>\n",
       "      <td>8.419164</td>\n",
       "      <td>597900.423639</td>\n",
       "      <td>12894.065081</td>\n",
       "      <td>1.063199e+06</td>\n",
       "      <td>785176.190880</td>\n",
       "      <td>...</td>\n",
       "      <td>-1025.223865</td>\n",
       "      <td>18348.460040</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1230.088215</td>\n",
       "      <td>10.250096</td>\n",
       "      <td>1.024812e+06</td>\n",
       "      <td>101815.745499</td>\n",
       "      <td>105163.749149</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 833 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            x0             x1            x2           x3            x4  \\\n",
       "id                                                                       \n",
       "0.0  10.891876  832442.812375  20585.544083  1028.369495  1.163780e+06   \n",
       "1.0  11.512994  832442.898114           NaN  1012.624877  1.028911e+06   \n",
       "2.0  11.052185  832442.896307  20585.512844  1003.953827  9.231756e+05   \n",
       "3.0  11.642076            NaN           NaN  1004.672084  9.459461e+05   \n",
       "4.0  10.407121  832442.831424  20585.557007          NaN  9.957182e+05   \n",
       "\n",
       "            x5             x6            x7            x8             x9  ...  \\\n",
       "id                                                                        ...   \n",
       "0.0   9.199135  597900.477629           NaN  1.144294e+06  785176.201298  ...   \n",
       "1.0  10.906408  597900.458612   8127.016078  1.099166e+06  785176.258299  ...   \n",
       "2.0   9.212979  597900.426764  10738.092422  1.027863e+06  785176.223468  ...   \n",
       "3.0   9.553420  597900.450367  13524.096973  1.168144e+06  785176.254867  ...   \n",
       "4.0   8.419164  597900.423639  12894.065081  1.063199e+06  785176.190880  ...   \n",
       "\n",
       "            x823          x824       x825       x826         x827       x828  \\\n",
       "id                                                                             \n",
       "0.0  -855.549602  12176.073427  10.647729  10.916371  1220.065443   8.566724   \n",
       "1.0  -787.397942  10493.095660  10.586492   9.463962   917.094909  10.231822   \n",
       "2.0  -906.997242  10959.516944  10.769287  10.342160   637.027802  10.705461   \n",
       "3.0 -1011.742516  16845.309819  10.483830  10.594941  1114.069590  10.321063   \n",
       "4.0 -1025.223865  18348.460040        NaN        NaN  1230.088215  10.250096   \n",
       "\n",
       "             x829           x830           x831     y  \n",
       "id                                                     \n",
       "0.0  1.036263e+06   85338.558539  103088.664210  71.0  \n",
       "1.0  1.007163e+06   95695.020645  105161.109422  73.0  \n",
       "2.0  1.019955e+06   80253.299882  104177.051666  66.0  \n",
       "3.0  1.085442e+06            NaN  102746.516920  55.0  \n",
       "4.0  1.024812e+06  101815.745499  105163.749149  67.0  \n",
       "\n",
       "[5 rows x 833 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x = pd.read_csv('X_train.csv', index_col='id')\n",
    "\n",
    "df_y = pd.read_csv('y_train.csv', index_col='id')\n",
    "\n",
    "df_x['y'] = df_y.values\n",
    "df_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "T = 0.1\n",
    "corr = df_x.corrwith(df_x['y']).abs()\n",
    "corr.sort_values().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "71\n",
      "Test score for T: 0.1, , k: 60, a: 0.01, gamma: 0.005\n",
      "ETR: 0.000 (0.000), best: 0\n",
      "XGB: 0.000 (0.000), best: 0\n",
      "KRR: 0.700 (0.045), best: 0\n",
      "GBR: 0.000 (0.000), best: 0\n"
     ]
    }
   ],
   "source": [
    "cross_val = KFold(n_splits=10, shuffle=True)\n",
    "models = ['KRR']\n",
    "best = 0\n",
    "\n",
    "for T in [0.1]:\n",
    "    for k in [60]:\n",
    "        for alpha in [0.01]: #[0.2, 0.1, 0.05, 0.01]:\n",
    "            for gamma in [0.005]:\n",
    "                kernel = 'rbf'\n",
    "                \n",
    "\n",
    "                scores_test = [[] for _ in range(4)]\n",
    "                df_x = pd.read_csv('X_train.csv', index_col='id')\n",
    "\n",
    "                df_y = pd.read_csv('y_train.csv', index_col='id')\n",
    "\n",
    "                df_x['y'] = df_y.values\n",
    "                corr = df_x.corrwith(df_x['y']).abs()\n",
    "\n",
    "                #T = 0.1\n",
    "                cols = []\n",
    "                for idx, co in zip(corr.index, corr.values):\n",
    "                    if co >= T:\n",
    "                        cols.append(idx)\n",
    "\n",
    "                df_x = df_x[cols]\n",
    "                df_y = df_x.pop('y')\n",
    "                df_x = df_x.values\n",
    "\n",
    "                \n",
    "                X_imp, y_imp = impute(df_x, df_y, k)\n",
    "                \n",
    "                len_old = len(X_imp)\n",
    "                #X_imp = pd.DataFrame(df_x).fillna(0).values\n",
    "                X, y, mask = remove_outliers(X_imp, y_imp.reshape((len(y_imp), 1)))\n",
    "                X_imp, y_imp = df_x[mask, :], df_y.values[mask]\n",
    "                print(len_old - len(X_imp))\n",
    "\n",
    "                for id_train, id_test in cross_val.split(X_imp):\n",
    "                    X_train, y_train = np.array([X_imp[idx] for idx in id_train]), np.array([y_imp[idx] for idx in id_train])\n",
    "                    X_test, y_test = np.array([X_imp[idx] for idx in id_test]), np.array([y_imp[idx] for idx in id_test])\n",
    "\n",
    "                    y_train = y_train.reshape((len(y_train), 1))\n",
    "                    y_test = y_test.reshape((len(y_test), 1))\n",
    "                    \n",
    "                    #X_train, _ = impute(X_train, pd.DataFrame(y_train), k)\n",
    "                    #X_test, _ = impute(X_test, pd.DataFrame(y_test), k)\n",
    "\n",
    "                    scalerX = StandardScaler().fit(X_train)\n",
    "                    scalerY = StandardScaler().fit(y_train)\n",
    "\n",
    "                    X_train = scalerX.transform(X_train)\n",
    "                    X_test = scalerX.transform(X_test)\n",
    "\n",
    "                    y_train = scalerY.transform(y_train)\n",
    "                    y_test = scalerY.transform(y_test)\n",
    "\n",
    "                    imp = KNNImputer(n_neighbors=k).fit(X_train)\n",
    "\n",
    "                    X_train = imp.transform(X_train)\n",
    "                    X_test = imp.transform(X_test)\n",
    "\n",
    "                    if 'ETR' in models:\n",
    "                        #model = ExtraTreesRegressor(n_jobs=-1, max_depth=None, n_estimators=1000, min_samples_split=2, min_samples_leaf=1, verbose=0) = 63\n",
    "                        model = ExtraTreesRegressor(n_jobs=-1, max_depth=None, n_estimators=1000, min_samples_split=2, min_samples_leaf=1, verbose=0)\n",
    "                        model.fit(X_train, y_train.ravel())\n",
    "                        train_score = get_score(X_train, y_train, model, scalerY)\n",
    "                        test_score = get_score(X_test, y_test, model, scalerY)\n",
    "                        scores_test[0].append(test_score)\n",
    "                        print('{:.3f}\\t{:.3f}\\tETR'.format(train_score, test_score))\n",
    "                    else:\n",
    "                        scores_test[0].append(0)\n",
    "                    \n",
    "                    if 'XGB' in models:\n",
    "                        #model = XGBRegressor(n_estimators=1000, max_depth=None, eta=0.01, subsample=0.5, colsample_bytree=0.8, gamma=0.1) = 0.66\n",
    "                        model = XGBRegressor(\n",
    "                            n_estimators=1000, \n",
    "                            eta=0.01, \n",
    "                            gamma=0.1, \n",
    "                            max_depth=None, \n",
    "                            min_child_weight=1,\n",
    "                            max_delta_step=0,\n",
    "                            subsample=0.5,\n",
    "                            colsample_bytree=0.8,\n",
    "                            colsample_bylevel=1,\n",
    "                            colsample_bynode=1,\n",
    "                            reg_lambda=1,\n",
    "                            tree_method='exact',\n",
    "                            nthread=-1\n",
    "                        )\n",
    "                        \n",
    "                        model.fit(X_train, y_train)\n",
    "                        train_score = get_score(X_train, y_train, model, scalerY)\n",
    "                        test_score = get_score(X_test, y_test, model, scalerY)\n",
    "                        scores_test[1].append(test_score)\n",
    "\n",
    "                        print('{:.3f}\\t{:.3f}\\tXGB'.format(train_score, test_score))\n",
    "                    else:\n",
    "                        scores_test[1].append(0)\n",
    "\n",
    "                    if 'KRR' in models:\n",
    "                        #model = KernelRidge(alpha=0.01, kernel='rbf', gamma=0.005) = 0.69\n",
    "                        model = KernelRidge(alpha=alpha, kernel=kernel, gamma=gamma)\n",
    "                        model.fit(X_train, y_train)\n",
    "                        train_score = get_score(X_train, y_train, model, scalerY)\n",
    "                        test_score = get_score(X_test, y_test, model, scalerY)\n",
    "                        scores_test[2].append(test_score)\n",
    "                        \n",
    "                        #print('{:.3f}\\t{:.3f}\\tKRR'.format(train_score, test_score))\n",
    "                    else:\n",
    "                        scores_test[2].append(0)\n",
    "                    \n",
    "                    if 'GBR' in models:\n",
    "                        model = GradientBoostingRegressor(n_estimators=1000, n_iter_no_change=10)\n",
    "                        model.fit(X_train, y_train.ravel())\n",
    "                        train_score = get_score(X_train, y_train, model, scalerY)\n",
    "                        test_score = get_score(X_test, y_test, model, scalerY)\n",
    "                        scores_test[3].append(test_score)\n",
    "                        print('{:.3f}\\t{:.3f}\\tGBR'.format(train_score, test_score))\n",
    "                    else:\n",
    "                        scores_test[3].append(0)\n",
    "\n",
    "                    #print()\n",
    "                    \n",
    "                print(f'Test score for T: {T}, , k: {60}, a: {alpha}, gamma: {gamma}')\n",
    "                #print(\"score: {:.3f} ({:.3f})\".format(np.mean(scores_test[2]), np.std(scores_test[2]))) \n",
    "                #best = max(best, np.mean(scores_test[2]))\n",
    "                #print(\"Best: {:.3f}\".format(best))\n",
    "                #print()\n",
    "                m = ['ETR', 'XGB', 'KRR', 'GBR']\n",
    "                #best = max(best, np.mean(scores_test[2]))\n",
    "                for i in range(4):\n",
    "                    print(\"{}: {:.3f} ({:.3f}), best: {}\".format(m[i], np.mean(scores_test[i]), np.std(scores_test[i]), best))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/lib/python3.8/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but StandardScaler was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[69.79042381 75.10647671 70.07894731 72.4588414  68.10130379 75.22251949\n",
      " 61.36194571 58.71480583 83.6255523  75.65372272 58.45850399 83.90436129\n",
      " 72.61974031 78.53910276 56.93878939 86.63282787 70.85500889 77.114419\n",
      " 70.05174788 70.70640021 69.14389818 62.04770923 80.52563702 75.32623814\n",
      " 59.86820512 72.92735135 55.99219275 75.40977441 61.82217315 73.18980001\n",
      " 66.1890324  70.86345728 58.38744498 73.89766795 65.8712363  64.42545765\n",
      " 76.71796497 51.34043944 71.47331803 68.30486471 65.65543203 76.06391831\n",
      " 71.25626334 75.62175956 74.46903255 69.3561175  71.36262989 74.74501944\n",
      " 72.43827024 68.41088796 78.1469086  64.69400574 62.25705126 83.18216116\n",
      " 82.26433    69.19474162 67.47123663 69.45699059 71.20567147 58.61467671\n",
      " 60.49796615 74.2485915  62.51524682 72.67169041 72.61608143 56.39417263\n",
      " 68.28621182 77.05837157 64.06791134 73.16204328 58.60776843 76.2742983\n",
      " 68.34772854 60.21947616 65.91073976 72.76665491 75.41029363 60.70223339\n",
      " 79.74289592 82.86641327 77.27103113 79.7614512  68.43600119 72.27771295\n",
      " 58.95910252 61.56899924 56.33930611 78.24348616 76.02466317 84.30942754\n",
      " 67.38813726 68.46945928 75.57612435 69.19995541 74.86459305 52.85496195\n",
      " 70.56084587 67.29700016 73.00488942 76.04500537 78.76733127 81.57766846\n",
      " 77.59671737 85.44987813 80.05256068 63.37129098 60.15006859 67.69409024\n",
      " 73.71946076 61.5954851  69.1169014  70.26452133 73.8209772  54.41242792\n",
      " 70.05156727 74.12542879 73.31062917 79.4226561  72.92514916 72.91387617\n",
      " 79.02589243 77.97575454 59.53179861 57.12943613 72.55042039 66.32034612\n",
      " 57.16828477 79.25075433 75.67305794 72.03975296 56.87819725 74.14331627\n",
      " 63.69986938 57.17067799 76.65133623 52.80690779 75.85620482 73.10120255\n",
      " 78.24895066 73.66735818 71.38713625 62.96596558 72.55370226 71.42432857\n",
      " 81.91940215 55.32505181 71.96040185 57.76242761 74.80346722 73.72188001\n",
      " 74.36157584 73.029802   74.13174501 59.57726333 81.18552598 55.96808955\n",
      " 64.21436593 79.74513434 81.87482518 78.96325613 78.95090431 64.27619704\n",
      " 86.37764589 65.2978217  68.30229614 76.59906379 60.53623039 78.46699208\n",
      " 73.2621929  74.49544763 60.73927897 73.87216462 57.22964384 66.34674624\n",
      " 78.92352639 63.63531663 78.31319276 75.73317295 59.63495398 68.75968437\n",
      " 70.86375189 65.67038354 75.03695674 68.46138259 50.44741061 57.4892817\n",
      " 65.54256653 61.69907095 60.22845497 64.99763385 66.74130625 70.78836868\n",
      " 76.50780282 68.33376084 57.27039318 80.0891087  76.91964231 73.41106736\n",
      " 48.64556347 57.36463572 65.29629313 69.83325953 71.91782077 76.42902868\n",
      " 74.58576535 66.25411195 66.7062071  70.58229649 51.60688443 65.33705214\n",
      " 71.06815954 72.86876846 70.27503527 81.90569233 64.17867101 72.43275409\n",
      " 79.8452868  72.79987571 67.01046629 77.31558456 54.13720938 71.32852084\n",
      " 58.11130378 65.27365381 64.88920627 69.82639918 76.73413782 68.89902574\n",
      " 64.81940866 71.03576144 74.08998422 64.49291588 65.31218524 68.160222\n",
      " 73.18747177 77.62918127 67.83627004 75.23480459 80.23255833 59.86334182\n",
      " 56.39745931 48.83922218 71.34216703 65.71160178 70.02545467 65.48858799\n",
      " 58.23578447 75.44715901 81.45438086 54.49038977 60.45955697 66.75648663\n",
      " 69.66038932 62.58643999 67.09033198 80.9437029  74.31148678 74.40031461\n",
      " 68.56100187 61.47789967 69.6150826  76.70078893 58.44387139 81.56578515\n",
      " 75.91520606 70.35445084 67.95536248 80.78278822 73.47281087 80.54407044\n",
      " 73.67007207 69.63561797 74.91257153 56.88283452 63.64139964 82.61515478\n",
      " 62.8853576  60.88169629 67.82145772 75.97405457 67.13732472 69.74116781\n",
      " 78.6611024  60.28056778 70.1539628  80.86915029 68.30457077 64.4778394\n",
      " 56.24525086 74.47364541 68.95201634 66.11539554 81.37592409 65.48937299\n",
      " 75.52563369 71.70573964 72.62845192 67.30829877 68.05351338 60.52609496\n",
      " 76.09960556 69.78482482 75.09810685 75.71625138 58.35461735 57.60065043\n",
      " 72.99238125 60.92616424 77.62805267 62.52882878 77.17321363 72.52540799\n",
      " 68.73878826 65.35483408 64.86028518 66.91928057 66.88298109 72.67742398\n",
      " 67.32428746 64.66669402 72.89020535 71.96223145 60.50027368 67.83138333\n",
      " 72.42169913 72.86151534 55.70791941 58.59366952 75.2784589  65.57794677\n",
      " 76.81640082 52.69705667 58.92924242 65.00754421 63.47342649 65.25504349\n",
      " 60.54374229 78.83018345 74.22087617 77.83860862 63.7169689  72.62172443\n",
      " 55.89695007 65.98344788 66.15489629 80.88760549 73.66603465 75.35913424\n",
      " 79.94343055 69.56541523 75.54669362 68.05300611 76.7438578  79.19116045\n",
      " 60.6925863  69.88743347 50.99015114 66.80514637 57.76998198 83.1646923\n",
      " 61.90229275 61.15722112 79.16500777 82.46908075 68.62209549 70.06853034\n",
      " 72.50864676 77.04553274 83.38598985 74.18832413 67.17152749 68.66718419\n",
      " 62.55286833 57.04951103 58.98872583 69.50573158 72.9533834  60.34676506\n",
      " 77.92009931 75.05977127 69.82600099 73.83148829 67.87640868 64.92679561\n",
      " 71.36550098 78.00998703 67.71460503 85.81970048 63.11768931 63.25950368\n",
      " 65.99281711 68.39435837 59.83780051 77.35323269 81.30217006 59.51591646\n",
      " 68.90914403 58.29656217 65.79824844 68.29227747 71.16302225 73.44635591\n",
      " 83.65408214 83.5272431  59.21618609 62.45956966 62.06886035 62.20981708\n",
      " 75.69242326 60.86801138 69.78454021 58.89250904 75.47037094 78.54064517\n",
      " 62.15325592 69.39186041 62.43565563 66.98657664 72.80040303 64.98475598\n",
      " 60.82491767 78.97665406 59.61318186 77.00687257 78.28132061 63.83007291\n",
      " 65.07044193 55.23901478 58.9228461  66.27873006 65.5238633  58.78945735\n",
      " 56.84195061 68.72540691 65.6684249  58.39020484 78.81731489 66.68554569\n",
      " 73.39949827 75.98521325 69.2569548  70.95757702 73.78758719 72.68093436\n",
      " 68.77746231 77.00571256 75.12437939 57.79933727 72.21265825 74.23114841\n",
      " 53.35619918 78.54234894 58.26116237 61.44232508 65.73498163 68.44999116\n",
      " 72.97599446 74.41422149 62.15591744 67.68730067 70.88082539 61.38988569\n",
      " 64.1077662  74.81967348 70.31776806 73.5109297  78.75333293 62.61892219\n",
      " 66.92490922 71.44608529 66.81730388 65.06630171 75.36533442 77.16033584\n",
      " 62.94555731 57.19161613 63.07686373 76.3162558  76.71217657 76.01984647\n",
      " 51.61810418 70.98634386 52.61608876 80.40205752 81.0065106  58.69497468\n",
      " 71.90546765 66.79552082 54.52022343 65.66712204 66.00020165 62.03547149\n",
      " 74.02823503 80.1411089  74.0231536  71.71480846 64.2860175  77.47888678\n",
      " 67.04499356 57.84300721 73.24893989 70.6995067  61.74552947 75.68119589\n",
      " 70.13862319 64.6418909  52.13518649 78.59249599 72.98447865 73.19645981\n",
      " 83.60350276 64.56456395 81.60191804 71.73451167 50.20234984 76.81372241\n",
      " 75.13488848 59.24803933 79.7313896  86.59867591 60.92733392 71.9515618\n",
      " 71.17887679 61.15065419 78.6112083  80.72956919 69.57272016 73.19233301\n",
      " 84.59097665 69.52685416 71.22028453 70.47501255 75.61997934 76.81487347\n",
      " 62.31814305 70.74860849 77.91932889 60.23950957 72.42549434 71.88278402\n",
      " 68.31583012 60.88174339 52.52247831 66.74940562 78.29047258 71.67429629\n",
      " 66.15032083 61.81077573 70.20373931 70.12364523 56.14660419 73.01878538\n",
      " 59.14787872 78.56873165 80.33702219 76.04996799 66.72866916 72.52746863\n",
      " 76.47578762 77.1512119  62.57805211 75.024627   54.97475862 76.26117721\n",
      " 74.88477317 72.95870747 75.39180023 57.7582188  62.94287552 80.06896632\n",
      " 83.73972097 65.10676811 76.01824701 59.59212442 73.23043532 69.6892149\n",
      " 64.45122553 52.82887479 56.30027161 84.37177591 65.11331683 81.14300947\n",
      " 58.89334894 77.26006327 65.99025797 73.87099387 77.11796488 74.82839682\n",
      " 59.47192298 73.40710881 87.77144066 68.40657603 73.80695945 79.48064856\n",
      " 75.25706813 71.08018158 72.05745117 75.22209302 71.84263486 65.46755203\n",
      " 64.22623903 69.64389531 73.87212279 65.30049745 80.86930969 65.57300686\n",
      " 56.9849017  79.69639267 58.63357309 73.87996193 56.79902826 71.68343752\n",
      " 63.69456762 69.40555218 68.96907124 71.47493368 71.60070236 71.14706992\n",
      " 65.68691013 71.04546324 72.6600137  80.88480995 61.33341146 74.67969209\n",
      " 85.25532691 78.36833792 79.09379642 72.21838211 62.04885418 78.16349868\n",
      " 71.30012052 77.93008801 75.6992968  75.59495141 67.49072053 61.101793\n",
      " 76.37244783 77.88762688 61.76027282 65.97981046 74.21881899 57.27127899\n",
      " 73.37495747 79.93119424 65.58262796 69.11071659 55.40347511 56.38832081\n",
      " 77.38251467 67.19604569 82.1230841  71.89455277 80.25450819 69.24976985\n",
      " 71.20138693 56.57394856 76.78135973 75.12680466 65.78558133 56.5341989\n",
      " 79.62943846 72.23788507 67.00270382 76.44408345 78.28145019 75.94247899\n",
      " 69.36462661 69.69644924 76.72004741 74.98914422 59.28597433 63.26272384\n",
      " 74.5466471  62.5056636  75.3642166  81.0019601  70.99751391 80.183543\n",
      " 69.78250416 77.40350022 59.49911896 66.82764337 70.01674562 72.95959079\n",
      " 51.5475701  62.05580664 57.86982825 77.34044951 68.19747092 67.11957512\n",
      " 73.62409518 73.0836545  71.04359751 71.62076114 71.61603887 61.23718275\n",
      " 81.85147173 71.6744303  76.8977429  73.7216727  69.95712163 69.4840582\n",
      " 61.64092384 63.51901293 60.49377407 83.13132785 62.95458935 77.10964768\n",
      " 71.27038875 59.24080574 55.90458497 74.85928721 75.21737844 57.4117315\n",
      " 53.77965827 53.76945081 71.56056753 76.23166742 74.61241572 79.74333874\n",
      " 73.44283374 77.00500096 74.61963975 75.02557087 79.33099787 76.86595726\n",
      " 50.93341027 63.81784932 68.4482446  81.66574388 71.94659044 76.04903803\n",
      " 79.1631952  76.80489085 78.7803119  68.46900903 84.762499   79.39591831\n",
      " 74.38652107 73.45747434 53.49471715 69.06356396 80.05040841 85.30494566\n",
      " 71.33824982 82.40856941 79.20157422 57.34426963 52.89892554 70.37551105\n",
      " 52.15594774 65.33937685 58.04288178 59.98375722 55.83921685 82.00329584\n",
      " 58.25069237 71.94941673 71.68516878 68.77446967 64.54148882 72.23899683\n",
      " 74.77540882 56.12496161 64.39717618 80.81001412 69.55996771 78.49665713\n",
      " 70.48533643 61.05597128 65.80696291 55.34719179 74.16171284 75.29004696\n",
      " 67.17979496 74.88450844]\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "k = 60\n",
    "alpha = 0.01\n",
    "gamma = 0.005\n",
    "kernel = 'rbf'\n",
    "\n",
    "# Load data\n",
    "df_x = pd.read_csv('X_train.csv', index_col='id')\n",
    "\n",
    "df_y = pd.read_csv('y_train.csv', index_col='id')\n",
    "\n",
    "# Load test set\n",
    "df_test = pd.read_csv('X_test.csv', index_col='id')\n",
    "df_test = df_test[[x for x in cols if x != 'y']]\n",
    "\n",
    "df_x['y'] = df_y.values\n",
    "\n",
    "# Calculate correlation\n",
    "T = 0.1\n",
    "corr = df_x.corrwith(df_x['y']).abs()\n",
    "\n",
    "# Remove unimportant features\n",
    "cols = []\n",
    "for idx, co in zip(corr.index, corr.values):\n",
    "    if co >= T:\n",
    "        cols.append(idx)\n",
    "\n",
    "df_x = df_x[cols]\n",
    "df_y = df_x.pop('y')\n",
    "df_x = df_x.values\n",
    "\n",
    "#print(df_x.shape)\n",
    "\n",
    "# Impute data\n",
    "X_imp = KNNImputer(n_neighbors=k).fit_transform(df_x)\n",
    "y_imp = df_y.values\n",
    "                \n",
    "X, y, mask = remove_outliers(X_imp, y_imp.reshape((len(y_imp), 1)))\n",
    "X_imp, y_imp = df_x[mask, :], df_y.values[mask]\n",
    "\n",
    "\n",
    "# Create training set\n",
    "X_train, y_train = np.array(X_imp), np.array(y_imp).reshape((len(y_imp), 1))\n",
    "#print(y_train.shape)\n",
    "\n",
    "scalerX = StandardScaler().fit(X_train)\n",
    "scalerY = StandardScaler().fit(y_train)\n",
    "X_train = scalerX.transform(X_train)\n",
    "y_train = scalerY.transform(y_train)\n",
    "\n",
    "imp = KNNImputer(n_neighbors=k).fit(X_train)\n",
    "X_train = imp.transform(X_train)\n",
    "\n",
    "# Remove outliers\n",
    "#remove_outliers(X_train, y_train)\n",
    "\n",
    "# Fit Model\n",
    "model = KernelRidge(alpha=alpha, kernel='rbf', gamma=gamma)\n",
    "model.fit(X_train, y_train)\n",
    "train_score = get_score(X_train, y_train, model, scalerY)\n",
    "\n",
    "# Load test set\n",
    "df_test = pd.read_csv('X_test.csv', index_col='id')\n",
    "df_test = df_test[[x for x in cols if x != 'y']]\n",
    "\n",
    "# Impute\n",
    "X_test = scalerX.transform(df_test)\n",
    "X_test = imp.transform(X_test)\n",
    "\n",
    "\n",
    "# Predict\n",
    "y_hat = model.predict(X_test)\n",
    "#print(y_hat[:, 0])\n",
    "y_hat = scalerY.inverse_transform(y_hat)\n",
    "print(y_hat[:, 0])\n",
    "pd.DataFrame({'id': df_test.index, 'y': y_hat[:,0]}).set_index('id').to_csv('y_hat.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6e4e9f98eb68ad3b7c296f83d20e6de614cb42e90992a65aa266555a3137d0d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
